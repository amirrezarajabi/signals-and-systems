{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part(n,signal,sample_rate):\n",
    "    fourier = np.fft.fft(signal[(n-1)*2048:n*2048])\n",
    "    freq = np.fft.fftfreq(2048, 1/sample_rate)\n",
    "    crop = []\n",
    "    for i in range(2048):\n",
    "        if (100 <= freq[i] <= 5000):\n",
    "            crop.append((freq[i],fourier[i]))\n",
    "    max_fts=[-10000000]*6\n",
    "    max_freqs=[-10000000]*6\n",
    "    gap = 816\n",
    "    for i in range(len(crop)):\n",
    "        freq_tmp = crop[i][0]\n",
    "        fourier_tmp = crop[i][1]\n",
    "        if  (100 <= freq_tmp <= 100+gap):\n",
    "            if fourier_tmp>max_fts[0]:\n",
    "                max_fts[0]=fourier_tmp\n",
    "                max_freqs[0]=freq_tmp\n",
    "        elif (100+gap < freq_tmp <= 100+2*gap) :\n",
    "            if fourier_tmp>max_fts[1]:\n",
    "                max_fts[1]=fourier_tmp\n",
    "                max_freqs[1]=freq_tmp\n",
    "        elif (100+2*gap < freq_tmp <= 100+3*gap) :\n",
    "            if fourier_tmp>max_fts[2]:\n",
    "                max_fts[2]=fourier_tmp\n",
    "                max_freqs[2]=freq_tmp\n",
    "        elif (100+3*gap < freq_tmp <= 100+4*gap) :\n",
    "            if fourier_tmp>max_fts[3]:\n",
    "                max_fts[3]=fourier_tmp\n",
    "                max_freqs[3]=freq_tmp\n",
    "        elif (100+4*gap < freq_tmp <= 100+5*gap):\n",
    "            if fourier_tmp>max_fts[4]:\n",
    "                max_fts[4]=fourier_tmp\n",
    "                max_freqs[4]=freq_tmp\n",
    "        elif (100+5*gap < freq_tmp <= 5000):\n",
    "            if fourier_tmp>max_fts[5]:\n",
    "                max_fts[5]=fourier_tmp\n",
    "                max_freqs[5]=freq_tmp\n",
    "    return max_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noiseprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseprint(filename):\n",
    "    sample_rate,signal = scipy.io.wavfile.read(filename)\n",
    "    tmp = part(1,signal,sample_rate)\n",
    "    tmp.reverse()\n",
    "    noise_print = np.array([[x] for x in  tmp])\n",
    "    for i in range(2,len(signal)//2048):\n",
    "        tmp = part(i,signal,sample_rate)\n",
    "        tmp.reverse()\n",
    "        noise_print=np.append(noise_print, [[x] for x in  tmp], axis = 1)\n",
    "    return noise_print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data.append((\"1_prelude\",noiseprint(\"data/1_prelude.wav\")))\n",
    "data.append((\"2_love_is_blue\",noiseprint(\"data/2_love_is_blue.wav\")))\n",
    "data.append((\"3_chanson_du_toreador\",noiseprint(\"data/3_chanson_du_toreador.wav\")))\n",
    "data.append((\"4_el_bimbo\",noiseprint(\"data/4_el_bimbo.wav\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(song_spec, clip_spec, points_per_slice=6):    \n",
    "    song_flat = song_spec.flatten()\n",
    "    clip_flat = clip_spec.flatten()\n",
    "    \n",
    "    sim_window_size = points_per_slice - 1\n",
    "    score = 0\n",
    "    for anchor in range(clip_flat.shape[0] - points_per_slice):\n",
    "        anchor_y = anchor % points_per_slice\n",
    "        sim_window = clip_flat[anchor: anchor+sim_window_size]\n",
    "        for song_anchor in range(anchor_y, song_flat.shape[0] - points_per_slice - 1, points_per_slice):\n",
    "            if clip_flat[anchor] == song_flat[song_anchor]:\n",
    "                if np.count_nonzero((song_flat[song_anchor:song_anchor+sim_window_size] - sim_window) == 0) >= 4:\n",
    "                    score += 1\n",
    "    \n",
    "    score /= song_flat.shape[0]\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similarity(path):\n",
    "    clip = noiseprint(path)\n",
    "    maximum = similarity(data[0][1],clip)\n",
    "    index=0\n",
    "    print(path[5:-4]+\" similarity to \"+str(data[0][0])+\": \"+str(maximum))\n",
    "    for i in range(1,4):\n",
    "        tmp = similarity(data[i][1],clip)\n",
    "        print(path[5:-4]+\" similarity to \"+str(data[i][0])+\": \"+str(tmp))\n",
    "        if tmp>maximum:\n",
    "            maximum=tmp\n",
    "            index=i\n",
    "    print(path[5:-4]+\" is most similar to \"+str(data[index][0]))\n",
    "    #################\n",
    "    # for plot clip #\n",
    "    #################\n",
    "    \"\"\"\n",
    "    for i in range(clip.shape[1]):\n",
    "        for j in range(clip.shape[0]):\n",
    "            plt.scatter(i,clip[j][i])\n",
    "    \"\"\"\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip1 similarity to 1_prelude: 0.0012919896640826874\n",
      "clip1 similarity to 2_love_is_blue: 0.0016795865633074936\n",
      "clip1 similarity to 3_chanson_du_toreador: 0.0003875968992248062\n",
      "clip1 similarity to 4_el_bimbo: 0.004392764857881137\n",
      "clip1 is most similar to 4_el_bimbo\n"
     ]
    }
   ],
   "source": [
    "clip1 = most_similarity(\"clip/clip1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip2 similarity to 1_prelude: 0.003229974160206718\n",
      "clip2 similarity to 2_love_is_blue: 0.002325581395348837\n",
      "clip2 similarity to 3_chanson_du_toreador: 0.002325581395348837\n",
      "clip2 similarity to 4_el_bimbo: 0.0012919896640826874\n",
      "clip2 is most similar to 1_prelude\n"
     ]
    }
   ],
   "source": [
    "clip2 = most_similarity(\"clip/clip2.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip3 similarity to 1_prelude: 0.009819121447028423\n",
      "clip3 similarity to 2_love_is_blue: 0.002971576227390181\n",
      "clip3 similarity to 3_chanson_du_toreador: 0.001421188630490956\n",
      "clip3 similarity to 4_el_bimbo: 0.0007751937984496124\n",
      "clip3 is most similar to 1_prelude\n"
     ]
    }
   ],
   "source": [
    "clip3 = most_similarity(\"clip/clip3.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
